如果使用 ddp模式，TorchMetric内部会 sync_dist 通信聚合操作


on_step 和 on_epoch 同时使用，那么log()的 name 会追加 _step和 __epoch


on_epoch=True，才有得到均值 loss


This is section, model not to(device)
    def configure_model(self)


First move, model.to(device)
    def configure_optimizers(self):

global_step :  optimizer step times


# lightning 的 loss / accumulate ，影响收敛，因此需要下述代码乘回去
# 原因如下，正常情况，应该是平均后立刻 loss.backward()，累计梯度，但不 step
# 但是 lightning 无法 立刻 loss.backward(),只能等到 accumulate 才能
# 所以，需要将 loss 放大，当 step 等价于 accumulate 的 loss ，然后loss.backward()
return loss * self.trainer.accumulate_grad_batches


# 分布式的时候 loss * world_size，增加收敛速度
loss * self.trainer.accumulate_grad_batches * self.trainer.world_size